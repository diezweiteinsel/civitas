stages:
  - build
  - test
  - deploy
  - maintenance # to not fill up VM space

default:
  interruptible: true

variables:
  POSTGRES_DB_TEST: civitas_db_test
  POSTGRES_USER_TEST: civitas_user
  POSTGRES_PASSWORD_TEST: securepassword
  DATABASE_URL_TEST: "postgresql://${POSTGRES_USER_TEST}:${POSTGRES_PASSWORD_TEST}@db:5432/${POSTGRES_DB_TEST}"

# ---- BUILD (sanity builds only; no registry) ----
build-backend:
  stage: build
  image: docker:24.0
  services: ["docker:24.0-dind"]
  script:
    - docker build -t sanity-backend:ci ./backend

build-frontend:
  stage: build
  image: docker:24.0
  services: ["docker:24.0-dind"]
  script:
    - docker build --build-arg REACT_APP_API_URL="/api" -f frontend/Dockerfile -t sanity-frontend:ci .


# ---- TEST ---- # old version, hopefully works again
test-backend:
  stage: test
  image: python:3.11-slim
  services:
    - name: postgres:15
      alias: db
  variables:
    POSTGRES_DB: $POSTGRES_DB_TEST
    POSTGRES_USER: $POSTGRES_USER_TEST
    POSTGRES_PASSWORD: $POSTGRES_PASSWORD_TEST
    # for testing the pipeline, we hardcode the test DB URL here
    DATABASE_URL: "postgresql://civitas_user:securepassword@db:5432/civitas_db_test"
    DB_HOST: db
    SECRET_KEY: "a-test-secret-key"
    ALGORITHM: "HS256"
    DEV_SQLITE: "0"
  before_script:
    - apt-get update && apt-get install -y gcc libpq-dev
    - pip install pytest-cov
    - pip install -r backend/requirements-linux.txt
    - pip install -e backend/.
  script:
  - pytest backend/ --junitxml=report.xml --cov=backend --cov-report=xml:coverage.xml --cov-report=html:htmlcov --cov-report=term-missing
  - 'test -f report.xml || echo "<testsuite name=\"pytest\" tests=\"0\" failures=\"1\"><testcase classname=\"collection\" name=\"error\"><failure message=\"pytest crashed before producing report.xml\"/></testcase></testsuite>" > report.xml'
  coverage: '/TOTAL.*? (100(?:\.0+)?\%|[1-9]?\d(?:\.\d+)?\%)$/'
  artifacts:
    when: always
    reports:
      junit: report.xml
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml

# ---- DEPLOY (scp repo → build/run on VM) ----
deploy-to-vm:
  stage: deploy
  image: alpine:latest
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
  before_script:
    - apk add --no-cache git openssh-client tar gzip docker-cli-compose
    - eval $(ssh-agent -s)

    # --- validate and normalize the File variable to a real key file ---
    - test -f "$SSH_PRIVATE_KEY" || { echo "SSH_PRIVATE_KEY must be a File variable"; exit 1; }
    # strip CRLF safely into a new file
    - tr -d '\r' < "$SSH_PRIVATE_KEY" > id_deploy
    - chmod 600 id_deploy
    # sanity: must look like an OpenSSH private key and be usable (no passphrase)
    - grep -q "^-----BEGIN OPENSSH PRIVATE KEY-----" id_deploy || { echo "Not an OpenSSH private key"; exit 1; }
    - ssh-keygen -y -f id_deploy >/dev/null || { echo "Invalid or passphrase-protected key"; exit 1; }

    - ssh-add id_deploy

    - mkdir -p ~/.ssh && chmod 700 ~/.ssh
    - printf "Host *\n\tStrictHostKeyChecking no\n\tPort %s\n" "$SSH_PORT" > ~/.ssh/config

  script:
    - git config --global --add safe.directory "$CI_PROJECT_DIR"
    - git archive --format=tar HEAD | gzip > app.tar.gz

    # build backend.env LOCALLY (CI expands vars here) — no heredoc
    - printf '%s\n' \
      'DB_HOST=db' 'DB_PORT=5432' \
      "DB_NAME=$POSTGRES_DB" "DB_USERNAME=$POSTGRES_USER" "DB_PASSWORD=$POSTGRES_PASSWORD" \
      "POSTGRES_DB=$POSTGRES_DB" "POSTGRES_USER=$POSTGRES_USER" "POSTGRES_PASSWORD=$POSTGRES_PASSWORD" \
      "SECRET_KEY=$SECRET_KEY" "ALGORITHM=$ALGORITHM" \
      'DEV_SQLITE=0' 'SKIP_CREATE_ALL=0' 'ECHO_SQL=0' 'SEED_DEMO_DATA=1' \
      "ALLOWED_ORIGINS=$ALLOWED_ORIGINS" 'PYTHONPATH=/app' > backend.env 

      # derive pubkey + show fingerprint (no secret)
    - ssh-keygen -y -f id_deploy > id_deploy.pub
    - ssh-keygen -lf id_deploy.pub
    - ssh-keygen -y -f id_deploy > id_deploy.pub
    - cat id_deploy.pub
    # strict auth so it doesn’t try password
    - ssh -o BatchMode=yes -o PreferredAuthentications=publickey -p "$SSH_PORT" "$SSH_USER@$SSH_SERVER_IP" "echo OK" || true
    - ssh -p "$SSH_PORT" "$SSH_USER@$SSH_SERVER_IP" "echo PATH=\$PATH; which tar; which mkdir; which docker"

    - ssh -p "$SSH_PORT" "$SSH_USER@$SSH_SERVER_IP" "mkdir -p '$VM_DEPLOY_PATH'"
    - ssh -o BatchMode=yes -P "$SSH_PORT" "$SSH_USER@$SSH_SERVER_IP" "echo OK-SSH && whoami && hostname"
    - scp -P "$SSH_PORT" app.tar.gz "$SSH_USER@$SSH_SERVER_IP:$VM_DEPLOY_PATH/app.tar.gz"
    - scp -P "$SSH_PORT" backend.env "$SSH_USER@$SSH_SERVER_IP:$VM_DEPLOY_PATH/backend.env"

    # unpack, move .env, build & run — single SSH command, no multiline
    - |
      ssh -p "$SSH_PORT" "$SSH_USER@$SSH_SERVER_IP" "
        set -e
        cd '$VM_DEPLOY_PATH'
        export DOCKER_CONFIG=$VM_DEPLOY_PATH/.docker
        mkdir -p \$DOCKER_CONFIG
        tar -xzf app.tar.gz && rm -f app.tar.gz
        mkdir -p backend && install -m 600 backend.env backend/.env && rm -f backend.env
        docker compose -f docker-compose.prod.yml build --pull
        docker compose -f docker-compose.prod.yml up -d --remove-orphans
        docker compose ps
      "




  environment:
    name: production
    url: http://$SSH_SERVER_IP:1203

reset_deployment:
  stage: maintenance
  image: alpine:latest
  needs: ["deploy-to-vm"]
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
  when: manual

  before_script:
    - apk add --no-cache git openssh-client docker-cli-compose
    - eval $(ssh-agent -s)
    - test -f "$SSH_PRIVATE_KEY" || { echo "SSH_PRIVATE_KEY must be a File variable"; exit 1; }
    - tr -d '\r' < "$SSH_PRIVATE_KEY" > id_reset
    - chmod 600 id_reset
    - grep -q "^-----BEGIN OPENSSH PRIVATE KEY-----" id_reset || { echo "Not an OpenSSH private key"; exit 1; }
    - ssh-keygen -y -f id_reset >/dev/null || { echo "Invalid or passphrase-protected key"; exit 1; }
    - ssh-add id_reset
    - mkdir -p ~/.ssh && chmod 700 ~/.ssh
    - printf "Host *\n\tStrictHostKeyChecking no\n\tPort %s\n" "$SSH_PORT" > ~/.ssh/config

  script:
    - |
      ssh -p "$SSH_PORT" "$SSH_USER@$SSH_SERVER_IP" "
        set -e
        cd '$VM_DEPLOY_PATH'
        export DOCKER_CONFIG=$VM_DEPLOY_PATH/.docker
        mkdir -p \$DOCKER_CONFIG
        docker compose -f docker-compose.prod.yml down -v
        docker compose -f docker-compose.prod.yml pull
        docker compose -f docker-compose.prod.yml up -d --remove-orphans
        docker compose ps
      "
cleanup:
  stage: maintenance
  tags:
    - sopro-runner 
  image: docker:24.0

  variables:
    DOCKER_HOST: "unix:///var/run/docker.sock"
  when: manual
  script:
    - echo "Starting cleanup of Docker resources on the runner host. Current disk usage:"
    - df -h
    - echo "Running Docker system prune on the runner host..."
    - docker system prune -a -f --volumes
    - df -h
    - echo "Cleanup complete."