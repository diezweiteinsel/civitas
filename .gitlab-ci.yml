stages:
  - build
  - test
  - deploy

default:
  interruptible: true

variables:
  POSTGRES_DB_TEST: civitas_db_test
  POSTGRES_USER_TEST: civitas_user
  POSTGRES_PASSWORD_TEST: securepassword
  DATABASE_URL_TEST: "postgresql://${POSTGRES_USER_TEST}:${POSTGRES_PASSWORD_TEST}@db:5432/${POSTGRES_DB_TEST}"

# ---- BUILD (sanity builds only; no registry) ----
build-backend:
  stage: build
  image: docker:24.0
  services: ["docker:24.0-dind"]
  script:
    - docker build -t sanity-backend:ci ./backend

build-frontend:
  stage: build
  image: docker:24.0
  services: ["docker:24.0-dind"]
  script:
    - docker build --build-arg REACT_APP_API_URL="/api" -f frontend/Dockerfile -t sanity-frontend:ci .

# ---- TEST ----
test-backend:
  stage: test
  image: python:3.11-slim
  services:
    - name: postgres:15
      alias: db
  variables:
    POSTGRES_DB: $POSTGRES_DB_TEST
    POSTGRES_USER: $POSTGRES_USER_TEST
    POSTGRES_PASSWORD: $POSTGRES_PASSWORD_TEST
    # for testing the pipeline, we hardcode the test DB URL here
    DATABASE_URL: "postgresql://civitas_user:securepassword@db:5432/civitas_db_test"
    DB_HOST: db
    SECRET_KEY: "a-test-secret-key"
    ALGORITHM: "HS256"
    DEV_SQLITE: "0"
  before_script:
    - apt-get update && apt-get install -y gcc libpq-dev
    - pip install -r backend/requirements-linux.txt
    - pip install -e backend/.
  script:
    # Always emit a JUnit file, even on collection errors
    - pytest backend/ --junitxml=report.xml || true
    - 'test -f report.xml || echo "<testsuite name=\"pytest\" tests=\"0\" failures=\"1\"><testcase classname=\"collection\" name=\"error\"><failure message=\"pytest crashed before producing report.xml\"/></testcase></testsuite>" > report.xml'
    # Fail the job if pytest failed
    - 'grep -q "<failure" report.xml && exit 1 || true'
  artifacts:
    when: always
    reports:
      junit: report.xml

# ---- DEPLOY (scp repo → build/run on VM) ----
deploy-to-vm:
  stage: deploy
  image: alpine:latest
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
  before_script:
     - apk add --no-cache openssh-client tar gzip docker-cli-compose
     - eval $(ssh-agent -s)
     - ssh-add "$SSH_PRIVATE_KEY"          # GitLab writes the file and gives you the path
     - mkdir -p ~/.ssh && chmod 700 ~/.ssh
     - printf "Host *\n\tStrictHostKeyChecking no\n" > ~/.ssh/config

  script:
    - git config --global --add safe.directory "$CI_PROJECT_DIR"
    - git archive --format=tar HEAD | gzip > app.tar.gz

    # build backend.env LOCALLY (CI expands vars here) — no heredoc
    - printf '%s\n' 'DB_HOST=db' 'DB_PORT=5432' \
      "DB_NAME=$POSTGRES_DB" "DB_USERNAME=$POSTGRES_USER" "DB_PASSWORD=$POSTGRES_PASSWORD" \
      "SECRET_KEY=$SECRET_KEY" "ALGORITHM=$ALGORITHM" \
      'DEV_SQLITE=0' 'SKIP_CREATE_ALL=0' 'ECHO_SQL=0' \
      "ALLOWED_ORIGINS=$ALLOWED_ORIGINS" 'PYTHONPATH=/app' > backend.env

    - ssh "$SSH_USER@$SSH_SERVER_IP" "mkdir -p '$VM_DEPLOY_PATH'"
    - scp app.tar.gz "$SSH_USER@$SSH_SERVER_IP:$VM_DEPLOY_PATH/app.tar.gz"
    - scp backend.env "$SSH_USER@$SSH_SERVER_IP:$VM_DEPLOY_PATH/backend.env"

    # unpack, move .env, build & run — single SSH command, no multiline
    - ssh "$SSH_USER@$SSH_SERVER_IP" "set -e; cd '$VM_DEPLOY_PATH'; \
        tar -xzf app.tar.gz && rm -f app.tar.gz; \
        mkdir -p backend; install -m 600 backend.env backend/.env; rm -f backend.env; \
        docker compose -f docker-compose.prod.yml build --pull; \
        docker compose -f docker-compose.prod.yml up -d --remove-orphans; \
        docker compose ps"


  environment:
    name: production
    url: http://$SSH_SERVER_IP:1203

